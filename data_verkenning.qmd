<!--Let op: Figuren en tabellen in het Engels!! -->

```{=html}
<!--
vragen aan Francis:
* Hoe food&feed beter categoriseren --> zelf nakijken
* ok om in data cluster voor kluisbos de NA te vervangen door water cycle related services?
* ok om gemiddelde unieke score te gebruiken voor de common score?

to do:
* vragen zijn nu puur op data beantwoord --> modelmatig
* omzetten naar een model (eventueel hurdle model zoals in thesis)
* afronding aanpassen naar mail
* nakijken clustering vergelijken met definities in Data (zelfde excel file)
-->
```

# Data verkenning

```{r setup, include=FALSE}
#| include: false
#| #| message: false
#| warning: false
#| results: hide
library(tidyverse)
library(readxl)
library(INBOtheme)


data_ana <- readRDS("interim/data_ana.rds") 
data_avg <- readRDS("interim/data_avg.rds")

data_smry <- data_ana |>
  group_by(case_short, ess_short, f_score) |>
  summarise(n = n(),
            .groups = "drop")

```


## Data inhoud

De data bestaat uit `r nrow(data_ana)` rijen en `ncol(data_ana)` kolommen. De kolommen zijn: `r paste(colnames(data_ana), sep = ", ")`. De data is ingelezen en de kolomnamen zijn omgezet naar kleine letters. De kolomnamen zijn: `r colnames(data_ana) |> paste(collapse = ", ").

Verder valt op dat in de data voor de cases "Gelinden" en "De Wijer" er geen link is tussen respondent en antwoord, dus er is geen effect van respondent op antwoord mogelijk om te detecteren in die gevallen.

Alle cases worden herleid op ess_common niveau door een gewogen gemiddelde te pakken van de ess_unique scores. Voor de cases "Gelinden" en "De Wijer" wordt het gemiddelde genomen van de scores per ess_unique. Voor de overige cases wordt het gemiddelde genomen van de scores per respondent en deze worden dan uitgemiddeld over de ess_unique.

In de analyse op de vereenvoudigde data zal geen rekening gehouden worden met het respondent-effect.

## Vergelijking categorisering en ruwe data

De categorieën in de data zijn vergeleken met de categorisering in de data van de ESS. Deze komen niet volledig overeen, maar de verschillen zijn niet groot:

- Er wordt een categorie "Bio-production" gebruikt in de data, die de categorieën "Food & feed production" en "Wood & fibre production" samenvoegt.
- Er zijn enkele verschillen in het gebruik van hoofdletters en spaties, maar de categorieën komen overeen.
- In de categorisering wordt vaak tussen haakjes nog extra informatie gegeven die in de data niet voorkomt, zoals bv "Fishery" en "Fishery (recreative & professional)".
- In het kluisbos wordt de categorie "Water cycle related services" gebruikt bij de waarden die NA zijn in de data.

Er is gekozen de categorisering in de data te gebruiken en niet deze in het tabblad rond categorisering van de Excel file omdat het makkelijker is om te werken met de kortere namen.

## Aanpassen scores

Om naar een ordinaal scoringssysteem te komen is de originele score `score_origineel` aangepast naar een score `score` die loopt van -1 tot 3. De originele score is afgerond naar het dichtstbijzijnde hoger gelegen gehele getal:

- 0.6 en 0,75  -> 1
- 1.2 en 1.5 en (1.8) -> 2  
- 2.25 en 2.4 -> 3

Er wordt ook een kolom f_score gemaakt die een ordinale factor is van de score, met niveaus van 1 tot 5 (dus score + 2) zodat deze gebruikt kan worden in de analyse.


Hieronder volgt een overzicht van namen en afkortingen die gebruikt worden in de data. Daarnaast is een overzicht van de ESS categorieën per case weergegeven.

```{r tab-defcases}


n_respondents <- data_ana |> 
  group_by(case, case_short, ess_common, ess_short) |>
  summarise(respondents = n(), .groups = "drop")
  
tb_cases <- data_ana |>
  left_join(n_respondents |>
              group_by(case) |>
              summarise(n_resp = max(respondents),
                        n_ess = length(unique(ess_short))),
            by = "case")

DT::datatable(tb_cases |> 
                group_by(case, case_short) |>
                summarise(n_resp = max(n_resp),
                          n_unique_ess = n_distinct(ess_unique),
                          n_ess = max(n_ess),
                          .groups = "drop") |> 
                select(case, n_resp, n_ess) |>
                distinct() |> 
                arrange(case),
              colnames = c("Case",
                           "Number of respondents",
                           "Number of Unique ESS",
                           "Number of common ESS"),
              options = list(pageLength = 15, autoWidth = FALSE),
              caption= "Overview of cases and number of respondents")

```

```{r tab-defess}

tb_ess <- data_ana |> 
  group_by(cluster_short, ess_common, ess_short) |> 
  summarise(n_unique_ess = n_distinct(ess_unique), 
            n_cases = n_distinct(case_short),
            cases = paste(unique(case_short), collapse = ", "),
            .groups = "drop")

DT::datatable(tb_ess,
              colnames = c("ESS cluster", "ESS common",
                           "ESS short",
                           "Nr of ESS combined", 
                           "Nr of cases",
                           "Cases"),
              caption = "Overview of ESS categories",
              options(list(pageLength = 12, autoWidth = FALSE)))

```

```{r fig-caseOverview}
#| eval: false
#| fig.cap: "Occurence of common ecosystem services across the case studies. Some cases have more than one service under the same common service name. Total cases are added to each bar, total services between brackets"
tb <- data_ana |>
  group_by(case_short, ess_short, ess_unique) |>
  summarise(n = n_distinct(ess_unique), .groups = "drop_last") |> 
  summarise(n_ess_common = n(), .groups = "drop") |>
  group_by(ess_short) |>
  mutate(total_ess = sum(n_ess_common)) |>
  arrange(desc(total_ess), ess_short, case_short)

totals <- tb |>
  group_by(ess_short) |>
  summarise(total_ess = sum(n_ess_common), .groups = "drop",
            distinct_cases = n_distinct(case_short)) |> 
  mutate(fig_entry = paste(distinct_cases, "(", total_ess, ")", sep = ""))

sorted_levels <- totals |> arrange((total_ess)) |> pull(ess_short)

ggplot(tb |> mutate(ess_short = factor(ess_short, levels = sorted_levels)),
       aes(x = ess_short, y = n_ess_common, fill = case_short)) +
  geom_bar(stat = "identity") +
  geom_text(data = totals, 
            aes(x = ess_short, y = total_ess, label = fig_entry), hjust = -0.1,
            inherit.aes = FALSE, color = "#888888") + coord_flip() +
  ylim(c(0, max(totals$total_ess) + 2)) +
  labs(fill = "case", y = "frequency of services", x = "common service name")


```

```{r caseoverview2a}
#| fig.cap: "Occurence of common ecosystem services across the case studies"
tb_common <- data_ana |> 
  group_by(case, ess_cluster, ess_common, ess_short, ess_unique) |>
  summarise(n_resp = n(), .groups = "drop_last") |> 
  summarise(n_resp = max(n_resp), .groups = "drop",
             n_ess_unique = n())

tb_cluster <- tb_common |> 
  group_by(case, ess_cluster) |>
  summarise(max_n_resp = max(n_resp),
            min_n_resp = min(n_resp),
            n_ess_common = n(), 
            n_ess_unique = sum(n_ess_unique),
            .groups = "drop") |> 
  mutate(total_unique = sum(n_ess_unique),
         total_common = sum(n_ess_common),
         fr_unique = n_ess_unique / total_unique,
         fr_common = n_ess_common / total_common,
         .by = c(case)) 

ggplot(tb_cluster, aes(x = case, y = fr_common, fill = ess_cluster)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "case", y = "percentage of common services", fill = "cluster") +
  coord_flip()
```

```{r caseoverview2b}
ggplot(tb_cluster, aes(x = case, y = fr_unique, fill = ess_cluster)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "case", y = "percentage of unique services", fill = "cluster") +
  coord_flip()
```

```{r caserespondents}

data_orig |> group_by(ess_short, case_acro, ess_unique) |> 
  summarise(n = n(), .groups = "drop_last") |> 
  summarise(min_n_resp = min(n), .groups = "drop") |> 
  pivot_wider(names_from = case_acro, values_from = min_n_resp, values_fill = 0) |> 
  knitr::kable(caption = "Minimum number of respondents per unique ESS category per case")


```

## Score verdeling

In @fig1 is de verdeling van de scores per case en ESD common weergegeven. Hier zie je duidelijk dat sommige esd common meer esd unique categorieën bevatten dan andere.

```{r fig1}
#| fig.cap: "Distribution normalised scores per case and ESD common"
#| fig.width: 8
#| fig.height: 11
ggplot(data_smry, aes(x = ess_short, y = n, fill = f_score)) +
geom_bar(position = "stack", stat = "identity") + 
  facet_wrap(~case, scales = "free_y", ncol = 2) +
 theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  labs(x = "ESS common (short)", y = "Frequency", fill = "Score") 
```

In @fig2 is de verdeling van de genormaliseerde scores per case en ESD common weergegeven. Op het eerste zicht is duidelijk dat jacht en gemotoriseerde recreatie over het algemeen niet gewenst zijn

```{r fig2}
#| fig.cap: "Distribution normalised scores per case and ESD common"
ggplot(data_processed |> 
          mutate(ess_short = reorder(ess_short, ess_order)),
        aes(x = ess_short, y = m_score, 
            color = case, group = case)) + 
   geom_line() + 
   geom_point() +
   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
   labs(x = "ESS common", y = "Mean score", color = "Case")
```

```{r fig3a}
#| fig.cap: "Distribution normalised scores per case and ESD common"
#| fig.width: 8
#| fig.height: 11

ggplot(data_processed, aes(x = ess_short, y = case_acro, 
            color = m_score, size = se_score)) +
  geom_point() + 
   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "ESS common", y = "Case", color = "Mean score", size = "SE score")
  coord_flip()

```

```{r fig3b}
#| fig.cap: "Distribution normalised scores per case and ESD common"
#| fig.width: 11
#| fig.height: 11

ggplot(data_processed, aes(x = ess_short, y = m_score, 
            color = case_acro, size = se_score)) +
  geom_point() + 
   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "Mean score", y = "ESS common", color = "Case", size = "SE score")
  coord_flip()

```

## Algemene gewenstheid en consensus

```{r algemenegewenstheiddata}
#| fig.cap: "Distribution of average wishedness per case"
case_scores <- data_processed |> 
  group_by(case) |> 
  summarize(n_system_services = n(),
            wishedness = mean(m_score, na.rm = TRUE),
            average_variation = sd(m_score, na.rm = TRUE), .groups = "drop") |> 
  arrange(desc(wishedness))

case_scores |> knitr::kable(caption = "Average wishedness ecosystem services per case")


ess_scores <- data_processed |> 
  group_by(ess_short) |> 
  summarize(n_cases = n(),
            wishedness = mean(m_score, na.rm = TRUE),
            average_variation = sd(m_score, na.rm = TRUE), .groups = "drop") |> 
  arrange(desc(wishedness)) 

ess_scores |> knitr::kable(caption = "Average wishedness ecosystem services")

```

```{r algemenegewenstheid1}
ggplot(data_processed |>
         mutate(case = factor(case, levels = rev(case_scores$case))) |>
         group_by(case) |>
         mutate(n_ess = n_distinct(ess_short)) |>
         ungroup() |>
         mutate(case = factor(case, levels = rev(case_scores$case))),
       aes(x = case, y = m_score)) +
  geom_boxplot() +  
  # Use a separate dataset with one row per ess_short for labels
  geom_text(data = . %>% 
              group_by(case, n_ess) %>% 
              slice(1) %>% 
              ungroup(),
            aes(y = -1.1, x = case, label = n_ess)) +
  coord_flip()
```

```{r algemenegewenstheid2}
#| fig.cap: "Distribution of average wishedness per ESS over the cases"
ggplot(data_processed |>
         mutate(ess_short = factor(ess_short,
                                   levels = rev(c(ess_scores$ess_short)))) |> 
         group_by(ess_short) |>
         mutate(n_cases = n_distinct(case)) |>
         ungroup() |>
         mutate(ess_short = factor(ess_short, levels = rev(ess_scores$ess_short))),
       aes(x = ess_short, y = m_score)) +
  geom_boxplot() +  
  # Use a separate dataset with one row per ess_short for labels
  geom_text(data = . %>% 
              group_by(ess_short, n_cases) %>% 
              slice(1) %>% 
              ungroup(),
            aes(y = -1.1, x = ess_short, label = n_cases)) +
  coord_flip()
```

```{r consensus1a}

levels_ess <- ess_scores |> 
  arrange(average_variation) |> 
  mutate(ess_short = factor(ess_short, levels = ess_short))

ggplot(data_processed |> 
         filter(!is.na(se_score)) |> 
         mutate(ess_short = factor(ess_short, 
                                   levels = levels_ess$ess_short)),
       aes(x = ess_short, y = se_score, color = case_acro)) + 
  geom_point() +
  coord_flip()

```

```{r consensus1b}

pd <- ess_scores |> 
  arrange(average_variation) |> 
  mutate(ess_short = factor(ess_short, levels = ess_short))

ggplot(pd, 
       aes(x = ess_short, y = average_variation, group = 1)) + 
  geom_line() +
  coord_flip()

```

```{r overzichtstabel}
score_cutoff <- c(-1, 0, 1, 2, 3)
score_breaks <- c("undesired", "mildy desired", "desired", "highly desired")
se_cutoff <- c(0, 0.375, 0.75, 1.5)
se_breaks <- c("consensus", "in-between", "disagreement")

ess_scores_tab <- ess_scores |> 
  mutate(score = cut(wishedness, breaks = score_cutoff, labels = score_breaks),
         se = cut(average_variation, breaks = se_cutoff, labels = se_breaks))

# Group the data and collect ESS names in each category
ess_grouped <- ess_scores_tab %>%
  #mutate(ess_short = gsub("&", "\\\\&", ess_short)) %>%
  group_by(score, se) %>%
  #summarise(ess_list = paste(ess_short, collapse = ", "), .groups = "drop") %>%
  summarise(ess_list = paste0("\n", paste(ess_short, collapse = "\n"), "\n")) |>  
  # Convert to wide format
  tidyr::pivot_wider(
    names_from = score,
    values_from = ess_list,
    values_fill = ""  # Empty string for missing combinations
  ) |> 
  select(se, "highly desired", "desired", "mildy desired", "undesired") |> 
  mutate(se = factor(se, levels = se_breaks)) |> 
  arrange(se)

# Create a markdown table with kable and kableExtra
ess_table <- ess_grouped %>%
  knitr::kable(format = "markdown", 
        col.names = colnames(ess_grouped),
        align = c("l", "l", "l", "l", "l")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = FALSE) %>%
  kableExtra::column_spec(2:4, width = "12em", background = "lightyellow") %>%
  kableExtra::row_spec(0, bold = TRUE)

# Print the table in R Markdown
ess_table

# # Alternative version with HTML formatting for better line breaks
# ess_table_html <- ess_grouped %>%
#   mutate(across(starts_with("SE Category"), ~gsub("\n", "<br>", .))) %>%
#   kable(format = "html", escape = FALSE,
#         col.names = c("Score", "SE Category 1", "SE Category 2", "SE Category 3")) %>%
#   kable_styling(bootstrap_options = c("striped", "hover"), 
#                 full_width = FALSE) %>%
#   column_spec(2:4, width = "8em") %>%
#   row_spec(0, bold = TRUE)
# 
# # For HTML output in R Markdown
# ess_table_html

```

## Gemaakte keuzes

Ik heb gekozen om de unieke ESS uit te middellen naar de common ESS. Dit is gedaan omdat er voor sommige cases geen link is tussen respondent en antwoord. Voor de overige cases is het gemiddelde genomen van de scores per respondent en deze zijn dan uitgemiddeld over de ess_unique. De standaardfouten worden dan berekend via variantiecomponentenanalyse. **Nog nachecken of dat wel correct is gebeurd**.

Een andere methode zou zijn om telkens random een unieke ESS te kiezen voor iedere common ESS, en dan moet dat verschillende keren gedaan worden om de modellen uit te middelen. Dit is een optie moest het hurdle model gekozen worden.

De scoring is nu van -1 tem 3 (maar ook 0 nog inclusief, dus 5 basislevels ipv 4, al laten de notities van Raisa beiden toe.) Doordat er geen herschaling is tussen -1 en 0, mag misschien niet zomaar het gemiddelde genomen worden in de statistische analyse, dus dan is het eerder het hurdle model, of een categorisch model (al moeten dan de kommagetallen weg). Nog beslissen.

Heeft het zin de clusters Food & feed production and Fibre & Bioenergy als aparte clusters te zien wat ze komen enkel voor in Kluisbos.

Ook analyse van samenhang voor waar dat mogelijk is.

<!--Let op: Figuren en tabellen in het Engels!! -->

```{=html}
<!--
vragen aan Francis:

* Hoe food&feed beter categoriseren: zelf nakijken
* ok om in data cluster voor kluisbos de NA te vervangen door water cycle related services?
* ok om gemiddelde unieke score te gebruiken voor de common score?

to do:
* vragen zijn nu puur op data beantwoord: modelmatig
* omzetten naar een model (eventueel hurdle model zoals in thesis)
* afronding aanpassen naar mail
* nakijken clustering vergelijken met definities in Data (zelfde excel file)
-->
```

# Data verkenning

```{r setup}
#| include: false
#| message: false
#| warning: false
#| results: "hide"

library(tidyverse)
library(here)
library(readxl)
library(INBOtheme)
#run before render
source(here("scripts", "_hulpfuncties.R"))
source(here("scripts", "data_import.R")) 
conflicted::conflict_prefer_all(c("dplyr"), quiet = TRUE)
```

```{r load-data}
#| warning: false
#| message: false
#| cache: true
data_ana    <- readRDS(here("interim", "data_ana.rds"))
data_avg <- readRDS(here("interim", "data_avg.rds"))
data_avg_ess <- readRDS(here("interim", "data_avg_ess.rds"))
data_avg_case <- readRDS(here("interim", "data_avg_case.rds"))


#Let op, houdt geen rekening met common maar unieke esd
data_smry <- data_ana |>
  summarise(n = n(),
            .groups = "drop")

inbostyle_colors <- colorRampPalette(colors = inbo_palette()[1:3])
score_colors <- c(inbo_rood, inbo_geel, inbo_lichtgroen, inbo_groen, inbo_donkerblauw)

n_cases <- length(unique(data_ana$case_short))
n_ess <- length(unique(data_ana$ess_short))

```

## Data integratie

### Hoofdlijnen

Er zijn 14 gebieden waarin er aan verschillende personen gevraagd werd om verschillende ecosysteemdiensten te scoren van ongewenst tot zeer gewenst. Deze 14 gebieden worden in de analyse gerefereerd als `cases (case_short)`. De personen worden gerefereerd als `respondenten`.

### Terminologie

In ieder gebied werden verschillende ecosysteemdiensten bevraagd, sommige overlappen, andere hebben een heel andere naam voor hetzelfde en nog andere zijn opgesplitst in veel kleinere ecosysteemdiensten. De bevraagde ecosysteemdiensten worden `unieke ecosysteemdiensten (ess_unique)` genoemd.

Deze worden geaggregeerd in `gemeenschappelijke ecosysteemdiensten (ess_common, ess_short)`, die in de tekst ook gewoon als `ecosysteemdiensten` benoemd worden.

Deze ecosysteemdiensten worden dan nog eens verder samengevoegd in `ecosysteemdiensten clusters (cluster_short)` of kortbenoemd `clusters`.

In dit verkennend hoofdstuk wordt vaak met een gemiddelde score gewerkt over cases of ecosysteemdiensten. Dit is gewoon het rekenkundig gemiddelde over de scores heen.

De consensus wordt berekend als 

$$
1 - \frac{SD(score)}{2}
$$
, waarbij de deling door 2 gewoon een normalisering is zodat de consensus altijd tussen 0 en 1 ligt. De maximaal mogelijke standaardeviatie is immers ongeveer 2 in een scoringssysteem van -1 tot 3. In de analysehoofdstukken worden andere maten van consensus gebruikt die ook rekening houden met het ordinale karakter van de scores.

### Beschrijving

De oorspronkelijke dataset bestaat uit 6215 rijen met evaluatiescores voor verschillende ecosysteemdiensten. Hiervan zijn er enkele vragen niet beantwoord geweest, waardoor de data zich beperkt tot `r nrow(data_ana)` rijen en `r ncol(data_ana)` kolommen. Er zijn ook 6 records weggelaten in de case Maarkebeek, die allemaal een -1 scoorden, maar ook slechts 2 vragen zouden beantwoord hebben, wat onlogisch lijkt.

De data werd ingelezen uit een excel bronbestand en de kolomnamen zijn omgezet naar kleine letters. De kolomnamen zijn:

```{r colames-data}
#| message: false
#| results: asis
colnam <- readr::read_csv2(here("data", "metadata_colnames.csv")) |>
  select(name, description)
cat(paste0("* **", colnam$name, "**: ", colnam$description), sep = "\n")

```

### Aanpassen scores

Om naar een ordinaal scoringssysteem te komen is de originele score `score_origineel` aangepast naar een score `score` die loopt van -1 tot 3. De originele score is afgerond naar het dichtstbijzijnde hoger gelegen gehele getal:

-   0.6 en 0,75 -\> 1
-   1.2 en 1.5 en (1.8) -\> 2\
-   2.25 en 2.4 -\> 3

Er wordt ook een kolom f_score gemaakt die een ordinale factor is van de score, met niveaus van 1 tot 5 (dus score + 2) zodat deze gebruikt kan worden in de ordinale analyse.

### Beperkingen in de dataset

In de data voor de cases "Gelinden" en "De Wijer" - deze laatste omvat 6 cases - is er geen link tussen respondent en antwoord, dus het is niet mogelijk een respondenteffect in rekening te brengen voor deze cases. Deze link zal dan ook niet gebruikt worden bij de analyse over de cases heen.

Doordat er heel veel unieke ecosysteemdiensten zijn (`r nrow(data_ana |> select(ess_cluster, ess_common, ess_unique) |> distinct())`), die verschillen tussen de verschillende cases, worden deze herleid tot een gemeenschappelijk niveau `ess_common` met `r nrow(data_ana |> select(ess_cluster, ess_common) |> distinct())` verschillende mogelijkheden. Elk van deze zijn op zich nog samengevoegd in ecosysteemdienstclusters (`r nrow(data_ana |> select(ess_cluster) |> distinct())`).

Spijtig genoeg komen de `ess_common` niet in alle cases voor, wat een grondige analyse bemoeilijkt.

In de analyse zal `ess_short` gebruikt worden, wat niet meer is dan een verkorte naam van `ess_common` alsook `case-short` als verkorte naam voor `case` 


### Data onder dezelfde noemer brengen

Er wordt gefocust om de data te analyseren per gemeenschappelijke ecosysteemdienst (ess_common, ess_short). Om tot die datasets te geraken worden de antwoorden van de unieke ecosysteemdiensten gewogen volgens het aantal unieke diensten per gemeenschappelijke dienst. Dus als een respondent 5 unieke diensten heeft gescoord als -1 ,0, 3, 3, 3, dan zal die voor 20% meetellen als -1, 20% als 0, en 60% als 3.

Bij de anonieme data (Gelinden, De Wijers) worden de antwoorden opgeteld per score en gedeeld door het aantal unieke diensten per gemeenschappelijke dienst, dus er wordt een soort uitmiddeling gedaan van het aantal respondenten. Dus bv subdienst 1 heeft 5 keer score 0 en 5 keer score 3, en subdienst 2 heeft 5 keer score 0 en 7 keer score 3, dan wordt dit samengeteld als 10 keer score 0 en 12 keer score 3, en dan gedeeld door de 2 ecosysteemdiensten, dus de score 0 krijgt 5 responses, de score 3 6 responses, het aantal respondenten die 10 en 12 waren, worden dus nu aanzien als 11 respondenten.

### Resultaten vergelijking ruwe data en gedefinieerde classificatie

De categorieën in de data zijn vergeleken met de categorisering in de data van de ESS. Deze komen niet volledig overeen, maar de verschillen zijn niet groot:

-   Er wordt een categorie `Bio-production` gebruikt in de data, die de categorieën `Food & feed production` en `Wood & fibre production` samenvoegt.
-   Er zijn enkele verschillen in het gebruik van hoofdletters en spaties, maar de categorieën komen overeen.
-   In de categorisering wordt vaak tussen haakjes nog extra informatie gegeven die in de data niet voorkomt, zoals bv `Fishery` en `Fishery (recreative & professional)`.
-   In het kluisbos wordt de categorie `Water cycle related services` gebruikt bij de waarden die niet overeenkomen in de categorisering.

## Data inhoud

### ESS categorieën

Hieronder volgt een overzicht van namen en afkortingen die gebruikt worden in de data. Daarnaast is een overzicht van de ESS categorieën per case weergegeven.

Er is een groot verschil in aantal respondenten per case, en ook de verschillende bevraagde ecosysteemdiensten verschillen sterk van case tot case, zelfs al worden ze geaggregeerd tot `ess_common`.

```{r tbl-defcases}
n_respondents <- data_ana |> 
  group_by(case, case_short, ess_unique, ess_common, ess_short) |>
  summarise(respondents = n(), .groups = "drop")
  
tb_cases <- data_ana |>
  left_join(n_respondents |>
              group_by(case) |>
              summarise(n_resp = max(respondents),
                        n_ess = length(unique(ess_short))),
            by = "case")

tb_cases_tab <- tb_cases |> 
  group_by(case, case_short) |>
  summarise(n_resp = max(n_resp),
            n_unique_ess = n_distinct(ess_unique),
            n_common_ess = max(n_distinct(ess_common)),
            .groups = "drop") |> 
  select(case, case_short, n_resp,n_unique_ess, n_common_ess) |>
  distinct() |> 
  arrange(case)

DT::datatable(tb_cases_tab,
              colnames = c("Case",
                           "Short name",
                           "Number of respondents",
                           "Number of Unique ESS",
                           "Number of common ESS"),
              options = list(pageLength = 15,
                             autoWidth = TRUE,
                             dom = "t"),
              rownames = FALSE,
              caption= "Overview of cases and number of respondents")

```

Een volledig overzicht van alle "gemeenschappelijke" ecosysteemdiensten vind je in tabel @tbl-defess alsook in welke gebieden (cases) die bevraagd zijn.

```{r tbl-defess}

tb_ess <- data_ana |> 
  group_by(cluster_short, ess_common, ess_short) |> 
  summarise(n_unique_ess = n_distinct(ess_unique), 
            n_cases = n_distinct(case_short),
            cases = paste(unique(case_short), collapse = ", "),
            .groups = "drop")

DT::datatable(tb_ess,
              colnames = c("ESS cluster", "ESS common",
                           "ESS short",
                           "Nr of ESS combined", 
                           "Nr of cases",
                           "Cases"),
              options(list(pageLength = 36,
                           autoWidth = TRUE,
                           dom = "t")),
              rownames = FALSE,
              caption = "Overview of ESS categories",
)

```

### Verdeling ecosysteemdiensten

```{r fig-caseOverview}
#| fig-cap: "Occurence of common ecosystem services across the case studies. Some cases have more than one service under the same common service name. Total cases are added to each bar, total services between brackets"
tb <- data_ana |>
  group_by(case_short, ess_short, ess_unique) |>
  summarise(n = n_distinct(ess_unique), .groups = "drop_last") |> 
  summarise(n_ess_common = n(), .groups = "drop") |>
  group_by(ess_short) |>
  mutate(total_ess = sum(n_ess_common)) |>
  arrange(desc(total_ess), ess_short, case_short)

totals <- tb |>
  group_by(ess_short) |>
  summarise(total_ess = sum(n_ess_common), .groups = "drop",
            distinct_cases = n_distinct(case_short)) |> 
  mutate(fig_entry = paste(distinct_cases, "(", total_ess, ")", sep = ""))

sorted_levels <- totals |> arrange((total_ess)) |> pull(ess_short)

ggplot(tb |> mutate(ess_short = factor(ess_short, levels = sorted_levels)),
       aes(x = ess_short, y = n_ess_common, fill = case_short)) +
  geom_bar(stat = "identity") +
  geom_text(data = totals, 
            aes(x = ess_short, y = total_ess, label = fig_entry), hjust = -0.1,
            inherit.aes = FALSE, color = "#888888") + coord_flip() +
  ylim(c(0, max(totals$total_ess) + 2)) +
  ggplot2::scale_fill_discrete(type = inbostyle_colors(n_cases)) +
  labs(fill = "case", y = "frequency of services", x = "common service name")


```

Hieronder (figuur @fig-caseoverview2a) volgt een verdeling van het aantal unieke en gemeenchappelijke ecosysteemdiensten. Hun aantal verschilt sterk over de verschillende hoofdclusters maar ook tussen de cases zelf.

```{r fig-caseoverview2a}
#| fig-cap: "Occurence of unique and common ecosystem services across the case studies"
#| message: false
tb_common <- data_ana |> 
  group_by(case_short, cluster_short, ess_common, ess_short, ess_unique) |>
  summarise(n_resp = n(), .groups = "drop_last") |> 
  summarise(n_resp = max(n_resp), .groups = "drop",
             n_ess_unique = n())

tb_cluster <- tb_common |> 
  group_by(case_short, cluster_short) |>
  summarise(max_n_resp = max(n_resp),
            min_n_resp = min(n_resp),
            n_ess_common = n(), 
            n_ess_unique = sum(n_ess_unique),
            .groups = "drop") |> 
  mutate(total_unique = sum(n_ess_unique),
         total_common = sum(n_ess_common),
         fr_unique = n_ess_unique / total_unique,
         fr_common = n_ess_common / total_common,
         .by = c(case_short)) 

tb_cluster_fig  <- 
  bind_rows(
    tb_cluster |> 
      transmute(case_short, cluster_short,
                fraction = fr_unique, which = "unique"),
    tb_cluster |> 
      transmute(case_short, cluster_short,
                fraction = fr_common, which = "common"))

ggplot(tb_cluster_fig,
       aes(x = case_short, y = fraction, fill = cluster_short)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "case", y = "percentage of ecosystem services", fill = "cluster") +
  coord_flip() +
  facet_wrap(~which)
```

## Score verdeling

In @fig-fig1 is de verdeling van de scores per gemeenschappelijke ecosysteemdienst weergegeven. Niet iedere ecosysteemdienst komt in elke case voor.

Over het algemeen worden de meeste ecosysteemdiensten als positief ervaran, toch is dit in de case `Dijle` en in mindere mate `Gelinden` minder uitgesproken met scores die heel vaak 0 of 1 zijn in plaats van 2 of 3 in andere gebieden.

```{r fig-fig1}
#| fig-cap: "Distribution scores per case and ESD common"
#| fig-width: 8
#| fig-height: 11

fraction_data <- 
  data_ana |> 
  group_by(case_short, ess_short, f_score) |>
  summarise(n_resp = n(), .groups = "drop") |>
  group_by(case_short, ess_short) |>
  mutate(f_resp = n_resp / sum(n_resp)) 


# Create stacked barplot
ggplot(fraction_data, aes(x = ess_short, y = f_resp, fill = factor(f_score))) +
  geom_col() +
  facet_wrap(~ case_short, ncol = 2) +
  labs(x = "ESS common",
       y = "Fraction of Respondents", 
       fill = "Score",
       title = "Distribution of Scores by ESS and Case") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = score_colors) 

```

In @fig-fig2 is de verdeling van de genormaliseerde scores per case en ESD common weergegeven. Op het eerste zicht is duidelijk dat jacht en gemotoriseerde recreatie over het algemeen niet gewenst zijn

```{r fig-fig2}
#| fig-cap: "Distribution normalised scores per case and ESD common"

data_avg |>
  #order by mean level
  mutate(ess_short = factor(ess_short, 
                           levels = unique(data_avg_ess$ess_short[order(data_avg_ess$simple_mean)]))) |>
  #plot
  ggplot(aes(x = ess_short, y = mean_score, 
            color = case_short, group = case_short)) + 
  geom_line() + 
  geom_point() +
  scale_color_manual(values = inbostyle_colors(n_cases)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "ESS common", y = "Mean score", color = "Case")

```


```{r fig-fig3data}

# Option 1: Heatmap with consensus indicated by transparency/alpha
# Lower SE = higher consensus = more opaque
colorramp <- c("red","lightblue", "#93A0EE", "#0000FF", "#000066")
p1 <- data_avg |> 
  #reorder by mean
  mutate(ess_short = reorder(ess_short, mean_score, mean)) |> 
  #plot
  ggplot(aes(x = ess_short, y = case_short, 
             fill = mean_score, alpha = consensus)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = colorramp,
    values = scales::rescale(c(-1, 0, 1, 2, 3)),
    name = "Mean\nScore",
    breaks = c(-1, 0, 1, 2, 3),
    labels = c("-1", "0", "1", "2", "3")) +
  scale_alpha_continuous(name = "Consensus\n(1/SD)", range = c(0.3, 1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "ESS", y = "Case", 
       title = "Mean Score and Consensus by Case and ESS",
       subtitle = "Color = Mean Score, Opacity = Consensus (higher = more consensus)")

# Option 3: Bubble chart with consensus as inverse size
p3 <- data_avg |>
  mutate(ess_short = reorder(ess_short, mean_score, mean)) |>
  ggplot(aes(x = ess_short, y = case_short, 
             color = mean_score, size = consensus)) +
  geom_point() +
  scale_color_gradientn(colors = colorramp,
                        values = scales::rescale(c(-1, 0, 1, 2, 3)),
                        name = "Mean\nScore",
                        breaks = c(-1, 0, 1, 2, 3),
                        labels = c("-1", "0", "1", "2", "3")) +
  scale_size_continuous(name = "Consensus", range = c(1, 6)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "ESS", y = "Case", 
       title = "Mean Score and Consensus by Case and ESS",
       subtitle = "Color = Mean Score, Size = Consensus (larger = more consensus)")
```

Figuur @fig-plotdatasummary3 toont in 1 oogopslag welke ecosysteemdiensten gewenst zijn per case, en hoeveel consensus er is binnen een case voor die dienst.

```{r fig-plotdatasummary3}
#| fig-cap: "Distribution normalised scores per case and ESD common"
#| fig-width: 11
#| fig-height: 4.7
print(p3)

```


Figuur @fig-fig3b toont deze informatie in een formaat om de algemene gewenstheid en consensus per ecosysteemdienst te kunnen zien.

```{r fig-fig3b}
#| fig-cap: "Distribution normalised scores per case and ESD common"
#| fig-width: 11
#| fig-height: 11

ggplot(data_avg |> 
         mutate(ess_short = reorder(ess_short, mean_score, mean)), aes(x = ess_short, y = mean_score, 
            color = case_short, size = consensus)) +
  geom_point(alpha = 0.5) + 
  geom_line(data = data_avg |> summarise(avg = mean(mean_score),
                                           .by = ess_short),
             aes(x = ess_short, y = avg, group = 1),
             inherit.aes = FALSE) +
  geom_point(data = data_avg |> summarise(avg = mean(mean_score),
                                           .by = ess_short),
             aes(x = ess_short, y = avg),
             pch = "x",
             size = rel(3),
             inherit.aes = FALSE) +
  scale_color_manual(values = inbostyle_colors(n_cases)) + 
   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = "ESS", y = "Mean score", color = "Case", size = "Concensus") 

```

## Algemene gewenstheid en consensus

De algemene gewenstheid van ecosysteemdiensten zal verschillen van case tot case:

-   sommige ecosysteemdiensten zijn relevanter voor specifieke cases
-   er wordt niet altijd veel meerwaarde gezien
-   er worden verschillende ecosysteemdiensten bevraagd per case

```{r tbl-algemenegewenstheiddata_case}
case_scores <- data_avg |> 
  group_by(case_short) |> 
  summarize(n_system_services = n(),
            wishedness = mean(mean_score, na.rm = TRUE),
            average_consensus = mean(consensus, na.rm = TRUE),
            .groups = "drop") |> 
  arrange(desc(wishedness))

case_scores |>
  knitr::kable(
    caption = "Average wishedness of ecosystem services per case",
    col.names = c("case",
                  "different ESS",
                  "mean score",
                  "average consensus"))

```

```{r tbl-algemenegewenstheiddata_ess}
ess_scores <- data_avg |> 
  group_by(ess_short) |> 
  summarize(n_cases = n(),
            wishedness = mean(mean_score, na.rm = TRUE),
            average_consensus = mean(consensus, na.rm = TRUE),
            .groups = "drop") |> 
  arrange(desc(wishedness)) 

ess_scores |>
  knitr::kable(caption = "Average wishedness of ecosystem services",
               col.names = c("ESS",
                             "different cases",
                             "mean score",
                             "average consensus"))

```

```{r fig-algemenegewenstheid1}
#| fig-cap: "Distribution of average wishedness of ESS per case. On the left the number of ESS per case is shown"
ggplot(data_avg |>
         mutate(case = factor(case_short,
                              levels = rev(case_scores$case_short))) |>
         group_by(case) |>
         mutate(n_ess = n_distinct(ess_short)) |>
         ungroup() |>
         mutate(case = factor(case, levels = rev(case_scores$case_short))),
       aes(x = case, y = mean_score)) +
  geom_boxplot() +  
  # Use a separate dataset with one row per ess_short for labels
  geom_text(data = . %>% 
              group_by(case, n_ess) %>% 
              slice(1) %>% 
              ungroup(),
            aes(y = -1.1, x = case, label = n_ess)) +
  labs(x = "case", y = "mean score") + 
  coord_flip()
```

```{r fig-algemenegewenstheid2}
#| fig-cap: "Distribution of average wishedness of an ESS over the cases. On the left the number of cases per ESS is shown"
#| fig-height: 7
#| fig-width: 7
ggplot(data_avg |>
         mutate(ess_short = factor(ess_short,
                                   levels = rev(c(ess_scores$ess_short)))) |> 
         group_by(ess_short) |>
         mutate(n_cases = n_distinct(case_short)) |>
         ungroup() |>
         mutate(ess_short = factor(ess_short, levels = rev(ess_scores$ess_short))),
       aes(x = ess_short, y = mean_score)) +
  geom_boxplot() +  
  # Use a separate dataset with one row per ess_short for labels
  geom_text(data = . %>% 
              group_by(ess_short, n_cases) %>% 
              slice(1) %>% 
              ungroup(),
            aes(y = -1.1, x = ess_short, label = n_cases)) +
  labs(x = "ess", y = "mean score") +
  coord_flip()
```

```{r fig-consensus1a}
#| fig-cap: "Concensus per ESS"

levels_ess <- ess_scores |> 
  arrange(average_consensus) |> 
  mutate(ess_short = factor(ess_short, levels = ess_short))

ggplot(data_avg |> 
         dplyr::filter(!is.na(consensus)) |> 
         mutate(ess_short = factor(ess_short, 
                                   levels = levels_ess$ess_short)),
       aes(x = ess_short, y = consensus, color = case_short)) + 
  geom_point() +
  scale_color_manual(values = inbostyle_colors(n_cases)) + 
  coord_flip()

```

```{r fig-consensus1b}
#| fig-cap: "Average variation per ESS"
pd <- ess_scores |> 
  arrange(average_consensus) |> 
  mutate(ess_short = factor(ess_short, levels = ess_short))

ggplot(pd, 
       aes(x = ess_short, y = average_consensus, group = 1)) + 
  geom_line() +
  coord_flip()

```

<!-- TOT HIER DOORLOPEN -->

```{r tbl-overzichtstabel}
score_breaks <- c(-1, 0, 1, 2, 3)
score_labels <- c("undesired", "mildy desired", "desired", "highly desired")
se_breaks <- c(0, 0.375, 0.75, 1.5)
se_labels <- c("consensus", "in-between", "disagreement")
#gebaseerd op qnorm(mean = 0.5, sd = 0.25, p = c(0.025,1/3,2/3,0.975))
#consensus in vrij normaal verdeeld tussen 0 en 1
#0.5 als gemiddelde en 0.25 als sd zijn dan logische instelwaarden
cnss_breaks <- c(0,0.4,0.6,1) 
cnss_breaks <- quantile(ess_scores$average_consensus,
                        probs = c(0,1/3,2/3,1))
cnss_labels <- rev(se_labels)

ess_scores_tab <- ess_scores |> 
  mutate(score = cut(wishedness,
                     breaks = score_breaks,
                     labels = score_labels,
                     incluse.lowest = TRUE),
         consensus = cut(average_consensus,
                         breaks = cnss_breaks,
                         labels = cnss_labels,
                         include.lowest = TRUE),
         )

# Group the data and collect ESS names in each category
ess_grouped <- ess_scores_tab %>%
  group_by(score, consensus) %>%
  summarise(ess_list = paste(ess_short, collapse = "; "),
            .groups = "drop") |>  
  # Convert to wide format
  tidyr::pivot_wider(
    names_from = score,
    values_from = ess_list,
    values_fill = ""  # Empty string for missing combinations
  ) |> 
  select(consensus, "highly desired", "desired", "mildy desired", "undesired") |>
  mutate(consensus = factor(consensus, levels = rev(cnss_labels))) |> 
  arrange(consensus)

# Create a markdown table with kable and kableExtra
# Create a markdown table with kable and kableExtra
ess_table <- ess_grouped %>%
  mutate(across(where(is.character), ~ gsub(";", "<br>", .x))) |> 
  knitr::kable(format = "html",  # Changed from "markdown" to "html"
               caption = "Overview of ESS categories by wishedness (score mean, groups [2-3], [1-2], [0-1], [-1-0]) and consensus (divided in 3 equal parts)",
        col.names = colnames(ess_grouped),
        align = c("l", "l", "l", "l", "l"),
        escape = FALSE) %>%  # Added escape = FALSE
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = FALSE) %>%
  kableExtra::column_spec(2:4, width = "12em", background = "lightyellow") %>%
  kableExtra::column_spec(5, width = "12em", background =  "#FFCCCB") %>%
  kableExtra::row_spec(0, bold = TRUE)
# Print the table in R Markdown
ess_table


```

<!--
## Gemaakte keuzes


Een andere methode zou zijn om telkens random een unieke ESS te kiezen voor iedere common ESS, en dan moet dat verschillende keren gedaan worden om de modellen uit te middelen. Dit is een optie moest het hurdle model gekozen worden.

De scoring is nu van -1 tem 3 (maar ook 0 nog inclusief, dus 5 basislevels ipv 4, al laten de notities van Raisa beiden toe.) Doordat er geen herschaling is tussen -1 en 0, mag misschien niet zomaar het gemiddelde genomen worden in de statistische analyse, dus dan is het eerder het hurdle model, of een cumulatief logistisch model.

Heeft het zin de clusters Food & feed production and Fibre & Bioenergy als aparte clusters te zien wat ze komen enkel voor in Kluisbos. Dat wordt samengevoegd onder bioproductie.

Ook analyse van samenhang voor waar dat mogelijk is.
--->
